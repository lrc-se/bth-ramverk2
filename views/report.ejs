<h1>Redovisningar</h1>
<p>Här följer redovisningarna som hör till kursen.</p>
<h4>Kursmoment</h4>
<ul>
<% for(var i = 1; i <= 7; ++i) { -%>
    <%_ var x = (i < 7 ? "0" + i : 10); -%>
    <li><a href="#kmom<%= x %>">Kmom<%= x %></a>
<% } -%>
</ul>
<section id="kmom01">
    <h2>Kmom01</h2>
    <p>
        Bland det första jag gjorde, efter att ha <a href="https://dbwebb.se/forum/viewtopic.php?f=60&amp;t=6979">erhållit tillstånd</a>, var att slänga ut Pug. 
        Det känns bara onödigt och framför allt <em>ineffektivt</em> att hålla på och lägga på ytterligare lager ovanpå existerande tekniker, med därtill hörande begränsningar, bara för sakens skull – 
        jag vill se vad jag gör och ha hela min verktygslåda till hands utan att behöva göra allehanda krumbukter för att komma åt den. 
        Hela tanken med s.k. "logiklösa mallar" är dessutom i mitt tycke fel i grunden: man bör visserligen inte ha <em>affärslogik</em> i sina vyer, 
        men det mesta utöver de mest basala tillämpningarna kommer att kräva <em>presentations&shy;logik</em> – och att då behöva flytta ut denna <em>från</em> 
        presentations&shy;lagret bara för att mallsystemet inte stöder den fullt ut är bara kontra&shy;produktivt och upphäver sitt eget syfte.
    </p>
    <p>
        Efter att ha gått igenom <a href="https://github.com/expressjs/express/wiki#template-engines">hela listan</a> på tillgängliga vymotorer föll mitt val slutligen på 
        <a href="http://ejs.co/">EJS</a>, mycket på grund av de anledningar som nämns på dess webbplats. Kort sagt, och återigen, 
        det finns ingen anledning att dra in (och behöva lära sig) ett helt nytt mallspråk som varken ser ut eller känns som HTML (t.ex. Pug/<wbr>HAML) 
        eller kontroll&shy;strukturer som varken ser ut eller känns som JavaScript (t.ex. Nunjucks/<wbr>Jinja2) – åtminstone inte i en kurs som använder sig av just HTML och JavaScript.
    </p>
    <p>
        Med EJS blir tvärtom allt hur enkelt som helst, särskilt i och med att man med Node har tillgång till förenkla(n)de ES6-konstruktioner, och det är bara att köra på. 
        Det finns dock en begränsning i att det saknas inbyggt stöd för layoutfiler, så jag byggde till ett eget minimalt system för detta, på likartat sätt som i <strong>ramverk1</strong> 
        (se vidare nedan). Vad gäller själva webbplatsen som sådan är stil&shy;sättningen den här gången avskalad och sparsam.
    </p>
    <p>
        Integrationen mot de externa tjänsterna gick lika smärtfritt som i den förra kursen. Jag valde Scrutinizer för kodkvalitets&shy;biten i och med att vi redan använt den där, 
        så får vi se om den duger fullt ut även här. Jag passade också på att introducera ett nytt validerings&shy;verktyg (<a href="https://www.npmjs.com/package/ejs-lint">ejs-lint</a>) 
        för EJS-mallarna, som nu ingår i min <code>make test</code>-svit. CSSLint och JSCS har dock fått stryka på foten och jag har gjort några smärre ingrepp i ESLints konfiguration.
    </p>
    <p>
        Slutligen har jag gjort försök med att köra applikationen publikt på studentservern (en av de två, i alla fall), vilket efter lite om och men verkar fungera. 
        Förut&shy;sättningen är att man (jag) kör <code>npm install</code> efter varje publicering för att återställa utvecklings&shy;miljön, 
        men det kanske man får ta; det är ju alltid trevligt att kunna visa upp det man gör och inte bara skriva om det.
    </p>
    <h5>Om Express och vymotorer</h5>
    <p>
        När det kommer till Express känns det mesta igen. Ett ramverk är ett ramverk och de ingående delarna är av nödvändighet likartade – 
        det finns ett begränsat antal sätt att lösa ett och samma problem på, oavsett plattform och teknik. Det som är specifikt i det här fallet är hur komponenterna samverkar och anropas, 
        vilket i sin tur känns igen från <strong>linux</strong>-kursen och Node-servrarna där, men det rör sig i grund och botten om samma beståndsdelar som används på samma sätt rent principiellt.
    </p>
    <p>
        Något som dock skiljer är hur man skapar och hanterar <em>middleware</em>-kedjor och sedan blir tonvikten på funktioner (och funktions&shy;objekt) 
        liksom det asynkrona upplägget större i och med att det rör sig om JS. Dessutom är ramverket här också sin egen webbserver, vilket inte är fallet med ramverk för t.ex. PHP eller ASP.NET, 
        som körs som tjänster i en separat webbserver&shy;applikation.
    </p>
    <p>
        Att Express också innehåller ett inbyggt (och tämligen enkelt) system för vyhantering är också positivt, 
        eftersom det gör det lätt att själv välja teknik enligt ovan utan att behöva ändra någonting i den anropande koden. Universella gränssnitt är bra, 
        även om det kanske kunde funnits fler (eller ens några) likaledes universella möjligheter att göra/<wbr>skicka med inställningar. 
        Sedan hade ju jag föredragit att man valt någon annan standard&shy;motor än just Jade/Pug, särskilt i och med att denna utgör ett sådant stort avsteg från både JS och HTML.
    </p>
    <h5>Berätta om din katalog&shy;struktur och hur du organiserade din kod. Hur tänkte du?</h5>
    <p>
        Mina statiska filer ligger i <i>static/</i> och mina vyer i <i>views/</i>. Vad gäller själva applikations&shy;koden har jag skapat en katalog <i>app/</i> 
        som för tillfället innehåller två filer: <i>app.js</i> och <i>util.js</i>. Den förstnämnda skapar och exporterar <code>app</code>-objektet medan den sistnämnda innehåller gemensamma funktioner 
        (just nu endast layout&shy;funktionen till EJS).
    </p>
    <p>
        I <i>routes/</i> ligger dels route&shy;hanterarna i egna filer (just nu endast en: <i>default.js</i>) och dels <i>routes.js</i> 
        som använder de övriga filerna för att konfigurera de olika sökvägarna utifrån valda grund&shy;sökvägar. Upplägget påminner en del om det i <strong>ramverk1</strong> 
        och det är <i>app/app.js</i> ovan som ansvarar för att kicka igång denna procedur (med lite DI-tänk).
    </p>
    <p>
        Min <i>index.js</i> är, slutligen, högst minimal och startar i princip bara servern. Samman&shy;fattningsvis är koden starkt modulariserad där varje del är begränsad i sitt omfång, 
        vilket alltså även inkluderar distributionen mellan katalogerna.
    </p>
    <h5>Använde du någon form av scaffolding som Express erbjuder?</h5>
    <p>
        Nej, men jag kikade lite på den genererade exempel&shy;koden och anammade/<wbr>anpassade vissa saker därifrån. 
        Här föredrog jag alltså att bygga en egen grund från början istället för att backa tillbaka från och modifiera en färdig struktur jag inte skulle varit fullt ut bekväm med, 
        vilket annars skulle blivit fallet.
    </p>
    <h5>Jobbar du med Markdown för innehållet, eller annat liknande?</h5>
    <p>
        Nej, jag tycker det mest är skönt att slippa ifrån det, då jag upplever det som alltför begränsande. Ge mig vanlig HTML alla dagar i veckan.
    </p>
</section>
<section id="kmom02">
    <h2>Kmom02</h2>
    <p>
        Jag insåg ganska snabbt att jag inte kunde köra varken Docker for Windows <em>eller</em> Docker Toolbox (ja, jag är säker), så jag började utforska andra sätt att komma vidare på. 
        Eftersom dokumentationen för Toolbox tydligt säger att det verktyget inkluderar VirtualBox, för att skapa en Linux-VM som kör Docker&shy;motorn, som i sin tur kör behållaren som 
        <em>i sin tur</em> kör det man egentligen vill köra, så tänkte jag att jag borde kunna använda min existerande Debian-VM i just VirtualBox från <b>linux</b>-kursen i våras direkt istället.
    </p>
    <p>
        Jag startade därför upp denna och följde instruktionerna för att installera Docker CE för Debian, vilket förlöpte väl. 
        Efter att sedan ha installerat Docker Compose separat visade det sig att allting faktiskt fungerade som det skulle, trots alla dessa upprepade abstraktioner – 
        det är som en rysk docka, eller <i>Inception</i> om man så vill. Sedan behövdes det en del hand&shy;påläggning för att få till de öppna portarna och synkningen med det ordinarie kursrepot, 
        men det var småsaker i jämförelse. Så nu kör jag Node i Linux i Docker i Linux i VirtualBox i Windows...
    </p>
    <p>
        PHP-behållarna i <i>kmom02/docker</i> använder version 5.6, 7.0 och 7.1 och det finns en <i>index.php</i> i samma katalog som kort och gott kör <code>phpinfo()</code>, 
        vilket gör det enkelt att bekräfta att det verkligen är rätt version som svarar. Node-behållarna kör version 4, 8 och 9, 
        där den förstnämnda av någon anledning är betydligt segare att både starta och avsluta, men alla tre fungerar bra. Jag tog även bort den föreslagna miljö&shy;variabeln, 
        så att Node fortsatt kör i utvecklings&shy;läge för att fel&shy;meddelanden skall framgå. För båda momenten gäller att behållarna svarar på port 8101, 8102 respektive 8103.
    </p>
    <p>
        I övrigt har jag som flera andra uppdaterat repot (inklusive Travis-integrationen) till att använda <code>npm</code> istället för <code>make</code>, 
        vilket dock medförde att jag behövde lägga till <a href="https://www.npmjs.com/package/npm-run-all"><code>npm-run-all</code></a> 
        som ett beroende eftersom det annars inte går att få <code>npm</code> att köra flera skript i följd på ett sätt som fungerar konsekvent på både Windows (mitt system) och Linux 
        (dbwebb och de externa tjänsterna).
    </p>
    <p>
        Jag har lagt till skripten <code>htmlhint</code>, <code>stylelint</code>, <code>eslint</code> och <code>ejslint</code>, som motsvarar dem som tidigare kördes i makefilen, 
        samt ett samlande skript <code>lint</code> som kör dessa i följd (och inte avbryter exekveringen om ett av dem fallerar). Slutligen har jag uppdaterat <code>npm test</code> 
        som för närvarande bara kör just <code>npm run lint</code>, men tanken är att det skall in fler steg i den sekvensen vad det lider.
    </p>
    <h5>Har du jobbat med Docker eller andra virtuali&shy;serings&shy;tekniker innan?</h5>
    <p>
        Docker är nytt, men jag har tidigare använt VirtualBox för flera olika gäst-OS, så konceptet som sådant är jag bekant med.
    </p>
    <h5>Hur ser du på möjligheterna att använda dig av Docker för att jobba med test av ditt repo?</h5>
    <p>
        Ärligt talat känns det mest som en massa onödigt krångel, särskilt eftersom vi/jag (åtminstone så långt) inte har något reellt behov av att köra flera parallella versioner. 
        Det blir bara lager på lager på lager och det är symptomatiskt att även det <em>officiella</em> sättet att köra Docker på allt annat än de senaste versionerna av Windows och MacOS 
        (med Docker Toolbox) innebär virtualisering i flera steg, vilket knappast (läs: definitivt inte) är resurs&shy;effektivt någonstans.
    </p>
    <p>
        Så nej, jag är inte särskilt imponerad så långt (annat än av att det över huvud taget fungerar) och har svårt att se nyttan i det här fallet. Kanske det kommer? 
        Annars känns det mest som ännu ett i en lång rad av påbjudna saker som egentligen är gjorda för Unix/Linux och bara med nöd och näppe går att tvinga in på andra plattformar. 
        Dbwebbs redan kraftiga slagsida ifråga om vad som anses som <em>rätt och riktigt</em> blir allt tydligare...
    </p>
    <h5>Gick allt smidigt eller stötte du på problem?</h5>
    <p>
        Det största problemet var alltså att jag inte kunde installera Docker över huvud taget på vanligt sätt, men den alternativa vägen som beskrivs ovan fungerade oväntat bra – 
        faktiskt har allt fungerat felfritt från första stund. Uppenbarligen ligger det en hel del arbete bakom dessa verktyg, 
        även om det kanske inte egentligen är meningen att de skall användas på just det här sättet.
    </p>
    <p>
        Det enda lilla hindret jag stötte på var att <a href="https://github.com/nodejs/docker-node/blob/master/README.md#how-to-use-this-image">den officiella dokumentationen</a> 
        för hur man skulle konfigurera <code>docker-node</code> med Docker Compose inte fungerade – servern gick inte att nå utifrån – 
        så jag ändrade lite i formatet i konfigfilen för att bättre överens&shy;stämma med det i 
        <a href="https://dbwebb.se/kunskap/kom-igang-med-docker-som-utvecklingsmiljo#docker-compose">dbwebb-exemplet</a> istället, 
        som jag redan visste lirade med PHP. Efter det fungerade allt som det skulle.
    </p>
    <h5>Skapade du din egen image? Berätta om den.</h5>
    <p>
        Nej, det kändes inte motiverat i det här skedet – och särskilt inte att <em>publicera</em> någonting som bara är menat som ett test. 
        Jag är för övrigt fortsatt starkt emot krav som innebär just krav på att registrera sig hos tjänster man inte själv valt och 
        att där göra saker publikt tillgängliga som man själv inte tycker borde vara det.
    </p>
</section>
<section id="kmom03">
    <h2>Kmom03</h2>
    <p>
        Både redovisa-repot och applikationen använder <code>npm</code> istället för <code>make</code> fullt ut – den senare har inte ens någon makefil. 
        I båda fallen kör kommandot <code>npm test</code> först validatorerna och därefter enhetstesten, så vill man endast köra de sistnämnda är det <code>npm run tap</code> 
        som gäller istället (se vidare nedan). Jag har även passat på att städa en del i beroendena i och med att jag använder andra (och färre) verktyg än i standard&shy;utförandet av 
        kursen/<wbr>uppgifterna; <i>node_modules</i> är <a href="https://pbs.twimg.com/media/C3SOI-_WAAAM4Js.jpg">omfattande nog</a> som den är, så det är bara bra om det går att kapa bort saker där.
    </p>
    <p>
        Me-sidan har fått ett enkelt testfall bara för att se att det hela fungerar, men det känns mest konstlat och har inget egentligt värde då funktionen ifråga inte är att betrakta som allmän.
    </p>
    <h5>Berätta vilka tekniker/<wbr>verktyg du valde för enhetstest och kodtäckning och varför.</h5>
    <p>
        Som testverktyg valde jag <a href="http://www.node-tap.org/">Node Tap</a> för att det helt enkelt <em>kändes</em> bäst. 
        Verktygets skapare uttrycker dessa känslor väl på dess startsida, så istället för att upprepa allt ordagrant här hänvisar jag helt enkelt dit och säger <strong>+1</strong>, 
        men det här citatet är värt att lyfta fram:
    </p>
    <blockquote>JavaScript tests should be JavaScript programs; not English-language poems with weird punctuation.</blockquote>
    <p>
        Kodtäckningen sköts av <a href="https://www.npmjs.com/package/nyc">nyc</a> (Istanbul), som Node Tap inkluderar per standard, så det var bara att köra på. 
        Denna kombination kan även enkelt generera en Clover-rapport som Scrutinizer kan tolka, 
        så jag behövde inte dra in någon ytterligare tjänst utan kunde bara snickra ihop en passande konfigurations&shy;fil – och som vanligt gick allt igenom på första försöket.
    </p>
    <p>
        Något annat som är positivt är att det trots att mycket annat sägs i diverse manualer går alldeles utmärkt att köra och testa ES6-kod utan vidare med dessa verktyg, 
        så Babel göra sig icke besvär! En liten nackdel med Node Tap är att dokumentationen är rätt så sparsam, så det tog ett tag att klura ut hur jag skulle använda <code>beforeEach()</code>, 
        men testfallen för applikationen (se nedan) blev enklare och renare när detta väl var på plats. Jag gjorde även en egen liten modul&shy;laddare för att kringgå <code>require</code>-cachen, 
        så att man får en ny instans av modulen ifråga för varje deltest för att säkerställa isolation.
    </p>
    <h5>Berätta om din CI-kedja och reflektera över de val du gjorde.</h5>
    <p>
        Jag vet inte om det är så mycket att berätta, då den som sagt ser likadan ut som förut – och som i <b>ramverk1</b>. Det är bara konfigurations&shy;filerna som skiljer sig en del, 
        men funktions&shy;mässigt är det likvärdigt – och allt fortsätter att förlöpa finfint, utan problem i vare sig automatik eller exekvering. 
        Men för att upprepa använder jag alltså <a href="https://travis-ci.org/">Travis CI</a> som byggtjänst och <a href="http://scrutinizer-ci.com/">Scrutinizer</a> 
        för kodkvalitet och kodtäckning, vilket synes mig fullt tillräckligt.
    </p>
    <h5>Reflektera över hur det gick att integrera enhetstesten i olika Docker&shy;behållare och om du ser någon nytta med detta.</h5>
    <p>
        Detta var lite knivigare än sist då både dokumentationen och instruktionerna lämnar en del att önska, så det blev mycket exempel&shy;studier och <i>trial and error</i>. 
        I slutändan, efter många felsteg, gjorde jag så att varje behållare (jag har tre: senaste Node, Node 8 och Node 4) kör ett shellskript som först skriver ut Node&shy;versionen, 
        så att man säkert vet vilken miljö man befinner sig i, och sedan kör <code>npm test</code>.
    </p>
    <p>
        Rent tekniskt baseras mina behållare på <code>node:alpine</code> för att inte slösa så vansinnigt med diskutrymme och jag har lagt konfigurationen för Docker Compose i en egen fil 
        (<i>docker-compose-test.yml</i>) för att inte inkräkta på de tidigare behållarna som startar servern. Test&shy;behållarna startas med <code>npm run test1</code> o.s.v. 
        Jag har även gjort ett medvetet val att <em>inte</em> köra <code>npm install</code> inne i behållaren, utan förlitar mig på att detta gjorts i huvud&shy;katalogen först – 
        det känns bara dumt, slösaktigt och ineffektivt att duplicera detta monster hela <em>fyra</em> gånger i onödan. Det finns ju redan beroenden till huvud&shy;katalogen i form av källkoden, 
        så en sådan redundans känns inte motiverad här.
    </p>
    <p>
        Vad gäller användnings&shy;områden så inser jag nyttan av att kunna testa saker mot olika målmiljöer utan att behöva byta maskin, 
        men i ett större perspektiv ser jag faror med att bygga hela sin utvecklings- och, ännu värre, produktions&shy;miljö kring Docker. 
        Eftersom varje behållare är självständig och innehåller <em>hela</em> den stack den behöver blir det i slutändan ett oerhört ineffektivt utnyttjande av resurser – 
        vem skulle medvetet välja att köra tiotals olika instanser av <em>samma</em> operativ&shy;system, inklusive allt, i något annat sammanhang om man inte behöver det? – 
        och diskutrymmet försvinner i rasande takt. Någonstans måste man sansa sig också och inte se allt som spikar bara för att man hittat en hammare.
    </p>
    <h5>Hur väl lyckades du utvärdera TDD-konceptet och vilka är dina reflektioner?</h5>
    <p>
        Jag gjorde ett allvarligt försök att följa detta för ordliste&shy;modulen i applikationen (se nedan), men kunde förstås inte låta bli att <em>tänka</em> på hur koden skulle se ut i förväg. 
        Det känns helt bakvänt att jobba på det sättet – vilket det också är – och jag trivs inte alls med det. Den utbredda evangelismen – den absoluta tron på att man har hittat 
        <em>Den Sanna Vägen</em> och att alla andra synsätt är fundamentalt fel – bland metodens förespråkare verkar också frånstötande.
    </p>
    <p>
        Det finns gott om kritiska TDD-artiklar på nätet, många baserade på konkreta erfarenheter, och jag behöver inte upprepa alla invändningar här, 
        men en fallgrop jag ser som extra tydlig och allvarlig är att man riskerar – eller kanske t.o.m. <em>garanterat kommer</em> – att få ett för smalt fokus och tappar greppet om helheten, 
        vilket gör att system&shy;arkitekturen på högre nivå blir lidande. TDD uppmuntrar till att lösa ett problem (ett fallerande test) på enklast/<wbr>minsta möjliga sätt, 
        vilket kanske fungerar i sammanhanget av den testade <em>enheten</em> men inte nödvändigtvis är lämpligt i sammanhanget av det större <em>systemet</em>, 
        där det kan finnas andra parametrar att beakta – särskilt om man underlåter (eller helt enkelt glömmer) att refaktorisera och städa upp efter de inledande stegen.
    </p>
    <p>
        Det blir även ett orimligt stort fokus på och beroende av testfallen, vilket kan leda till skör och ofullständig kod om man inte ser upp – 
        bara för att koden passerar testen och kod&shy;täckningen ligger på 100&nbsp;% betyder det inte nödvändigtvis att den faktiskt gör det den skall i produktion, med fysiska användare. 
        Kort sagt, koden blir bara så bra som testfallen är och det är i de allra flesta fall <em>omöjligt</em> att täcka in <em>samtliga</em> 
        kombinationer av tillstånd som ett system kan uppnå under körning, även om alla kodgrenar berörs.
    </p>
    <p>
        Ett typexempel är PHP-funktionen <a href="http://php.net/manual/en/function.empty.php"><code>empty()</code></a>, 
        som om den används för att kolla efter saknade indata kommer att stå för en obehaglig överraskning den dag någon skriver in strängen <code>"0"</code> – 
        och har testfallen inte fångat detta under utvecklingen är koden fortfarande felaktig i grunden, oavsett vad test&shy;rapporterna visar.
    </p>
    <p>
        Det finns också en tydlig risk i att skriva sina egna test, eftersom eventuella missar och förbiseenden ifråga om specifika&shy;tionerna och funktionali&shy;teten 
        då även kommer att hamna i systemet – testen och koden delar av nödvändighet samma svaghet i dessa fall och det faktum att testfallen passerar ger då en falsk säkerhet. 
        Ur en rent praktisk synvinkel är det även knepigt att fullt ut upprätthålla mantrat att skriva testet först, eftersom detta ju måste ha något att testa, 
        oavsett om det fallerar eller inte. Därmed måste man även i många fall skriva tillfällig kod för att över huvud taget kunna köra testsviten, 
        så det blir en hel del fram-och-tillbaka ändå. 
    </p>
    <p>
        Så, för att sammanfatta: Tack, men nej tack.
    </p>
    <h5>Berätta om tankarna kring din klient/server-applikation och nämn de tekniker du använder.</h5>
    <p>
        Det här var den del av momentet som var överlägset knepigast och tog längst tid – innan jag ens hade skrivit en enda kodrad. 
        Jag har luftat svårigheterna i <a href="https://dbwebb.se/forum/viewtopic.php?f=60&amp;t=7005">forumet</a> och har efter responsen slutligen landat i någon form av plan.
    </p>
    <p>
        Jag har tidigare, i en annan kurs på ett annat lärosäte, med en annan plattform och på ett annat sätt (skrivbords&shy;applikation i Java), utvecklat en variant av spelet <i>Skissa & Gissa</i>, 
        som de något äldre (hrrm) bland oss kanske kommer ihåg från den gamla portalen Passagens storhetstid kring millennie&shy;skiftet – 
        det var många håltimmar som gick åt till detta när det begav sig. Efter att ha tjuvkikat på Kmom04 och de realtids&shy;möjligheter som detta erbjuder 
        (nån fördel skall man väl ha av att skjuta upp saker och ting) bestämde jag mig för att försöka åter&shy;implementera detta inom ramarna för denna kurs. 
        Se även <a href="/app">applikations&shy;sidan</a>.
    </p>
    <p>
        Efter att ha gått igenom koden för den gamla applikationen och filtrerat den genom ökad erfarenhet samt kunskap om de verktyg vi har att tillgå här ser jag betydande potential till 
        både förbättring och färdighets&shy;mässig utveckling – JavaScripts inbyggda asynkronism förenklar mycket och <i>Web Sockets</i> tillsammans med JSON ser trevligt ut. 
        Eftersom det av nödvändighet handlar om grafisk framställning ger upplägget också möjlighet att dyka ner i <code>&lt;canvas&gt;</code>-världen 
        samt erbjuder ett betydligt bättre och mer <i>passande</i> tillfälle att testa ett ordentligt SPA-/<wbr>frontend&shy;ramverk än vad me-sidan gör.
    </p>
    <p>
        Exakt hur jag gör är ännu öppet, då alla bitar inte är på plats ännu, men tanken är alltså att knåpa på så smått med under&shy;stödjande tekniker under de ordinarie kurs&shy;momenten 
        och sedan övergå till att bygga själva applikationen på allvar när vi går in i projektet – 
        och det var just insikten om att detta är tillåtet som gjorde att jag kände att jag kunde ta steget och slå in på den här vägen. Vi får se hur långt det håller...
    </p>
    <p>
        Applikationen är (eller kommer att bli) uppdelad i två repon – ett för klienten och ett för servern – där det sistnämnda just nu endast innehåller en enkel komponent som hanterar ordlistan, 
        vilket var det bästa jag kunde komma på att bryta ut för att testa så här inledningsvis.
    </p>
</section>
<section id="kmom04">
    <h2>Kmom04</h2>
    <p>
        Jag skrev först hela serverdelen av chatten i en stor klump, men så fort den uppnått fungerande status bröt jag ut själva socketdelen till en fristående, mer allmän komponent. 
        Planen är att använda den sistnämnda både för projektet och för modulen i Kmom06, både för att den är just allmän och för att chatt&shy;funktionen 
        kommer att vara en integrerad del i ett större realtids&shy;sammanhang i applikationen (se nedan) och alltså inte låter sig isoleras på ett enkelt sätt där.
    </p>
    <p>
        Efter att ha färdigställt klientdelen gav jag mig sedan på att skapa en testserie för serverdelen, vilket efter många problem började arta sig rätt bra med existerande verktyg. 
        Här använder jag ingen mockning, utan servern startas upp på nytt för varje test och det etableras riktiga anslutningar med riktiga meddelanden. 
        För att kunna testa alla ingående kommandon (se nedan) behövde testen hålla reda på ordningen hos skickade och mottagna meddelanden, 
        då dessa förekommer i en viss sekvens beroende på vad som händer (t.ex. att det skickas ut en uppdaterad användar&shy;lista till alla klienter efter att en ny person anslutit sig), 
        vilket krävde en del tanke&shy;verksamhet.
    </p>
    <p>
        Testen fungerar nu fint, men de är också något sårbara i och med att de förutsätter att meddelanden anländer till mottagaren i samma ordning som de skickades, 
        vilket inte nödvändigtvis kommer vara fallet i drift över det publika nätet, men så länge man testar i utvecklings&shy;miljön går det bra. 
        Visst skulle det gå att hantera osynkade ankomster också, men jag har inte haft tid eller ork att implementera den typen av uppsamling här.
    </p>
    <p>
        Slutligen är jag tveksam till om detta verkligen är att betrakta som <em>enhets</em>test – det känns mer som <em>funktions</em>test, 
        men jag ville i alla fall få med någon form av test här. Resten av me-servern är dock fortfarande otestad, då detta <em>definitivt</em> skulle vara fråga om det senare. 
        Notera även att klientsides&shy;skriptet också är undantaget, då detta är hårt knutet till DOM:en och inte är att betrakta som fristående – 
        det är för övrigt svårt att uppnå just fristående status över huvud taget i webbläsar&shy;miljö utan kompilering, så det får vara, åtminstone för stunden.
    </p>
    <h5>Är du ny på realtids&shy;programmering eller har du gjort liknande tidigare?</h5>
    <p>
        Jag har gjort liknande tidigare, med <i>stream sockets</i> i Java – det är som nämndes i förra momentet just detta som utgör inspirationen till den applikation jag valt. 
        Begreppen och teknikerna är jag därför bekant med, men de är som sagt enklare att hantera inom ramarna för JS och Node där allt (eller åtminstone det mesta) 
        är asynkront redan från början, så man behöver inte implementera själva multi&shy;trådningen på egen hand.
    </p>
    <h5>Hur gick det att jobba med konceptet realtids&shy;programmering i webben? Några reflektioner?</h5>
    <p>
        Egentligen inte; abstraktions&shy;lagret gör att det känns precis som att använda direkta anslutningar enligt ovan. 
        Det enda som är lite synd är att det inte finns integrerat stöd för timeouter, vilket skulle varit önskvärt. 
        I övrigt öppnar tekniken upp fler möjligheter än det fanns tidigare – eller åtminstone förenklar dem avsevärt, 
        då man slipper "fullösningar" av olika slag för att simulera realtids&shy;uppdateringar av <i>push</i>-typ.
    </p>
    <h5>Berätta om din chatt som du integrerade i redovisa-sidan.</h5>
    <p>
        För implementationen valde jag rena <i>Web Sockets</i>, med modulen <code>ws</code> på serversidan, då det kändes bättre att få koll på grundtekniken än att gå på en abstraktion direkt. 
        Koden utgår därmed från/<wbr>påminner om den i exemplen, hos både dbwebb och <code>ws</code>, men med en del egna förändringar, förbättringar och upplägg. 
        Servern kan logga händelser till terminalen, vilket slås på med en konfigurations&shy;egenskap i samband med initieringen, 
        men för att applikationen skall fungera i utloggat läge på studentservern är detta avslaget nu, liksom i testserien för att slippa utskrifter där.
    </p>
    <p>
        Chatt&shy;systemet bygger på ett enkelt JSON-protokoll av allmänt format: ett fält <code>cmd</code> (sträng) som betecknar det kommando som skall utföras och ett fält <code>data</code> 
        (godtycklig datatyp) som innehåller eventuella tillhörande data. Jag har även lagt till stöd för sub&shy;protokollet <code>"v1"</code> på enklast möjliga sätt, 
        nämligen att servern för närvarande förkastar alla andra protokoll&shy;förslag.
    </p>
    <p>
        Servern kan skicka fyra olika kommandon: <code>welcome</code> (anslutningen accepteras och klienten släpps in i chatten), <code>unwelcome</code> (klienten släpps inte in),
        <code>users</code> (lista på anslutna användare) samt <code>msg</code> (chatt&shy;meddelande), där det sistnämnda innehåller tidsstämpel, smeknamn och meddelande&shy;text. 
        Klienten kan förstå dessa och skicka två egna: <code>nick</code> (begär att få ansluta med ett visst smeknamn) och <code>msg</code> (skicka chatt&shy;meddelande). 
        Både klient och server har hjälpmetoder för att hantera protokoll&shy;formatet.
    </p>
    <p>
        Klienten är enkelt uppbyggd, där man först får välja smeknamn och serveradress. När man klickar på "Anslut" skickas en begäran om inloggning till servern, 
        som antingen accepterar denna eller avslår den om smeknamnet är upptaget. Om man släpps in dyker chatt&shy;fönstret upp tillsammans med en lista på anslutna användare till höger. 
        Skriver meddelanden gör man som vanligt och när man ledsnat klickar man på "Koppla från" och kan börja om från början. Layouten är även responsiv, med lite flexbox&shy;trick.
    </p>
    <p>
        Vad gäller extra&shy;uppgifterna har jag redan berört användar&shy;listan (#4) och eftersom jag skapar konkreta DOM-noder och använder <code>textContent</code>-egenskapen 
        på klientsidan tolkas meddelandena aldrig som HTML (#2). Den största pucken blev istället #1, där jag har skapat allmän kod för ping (i den fristående <code>ws-server</code>-modulen) 
        med stöd för godtyckliga timeoutvärden (30 sekunder i detta fall). Chattservern kan sedan känna igen ifall en anslutning avbrutits av denna anledning och skicka ut ett passande meddelande, 
        men eftersom det är svårt att simulera denna situation har jag bara kunnat testa koden genom att tillfälligt vända på villkoret, d.v.s. att det är ett <em>icke</em> 
        uteblivet "pong" som gör att man kastas ut. #3 har jag inte gjort.
    </p>
    <h5>Berätta om den realtids&shy;funktionalitet du väljer att integrera i din klient/server-applikation.</h5>
    <p>
        I princip hela spelet kommer att bygga på <i>Web Sockets</i>, då det är av vikt att alla anslutna spelare uppdateras om vad som händer – 
        vad som ritas och vad som sägs – direkt <em>när</em> det händer. WS-komponenten kommer därför att vara central i applikationen, 
        både på servern och i klienten, där ett JSON-protokoll sedan står för data&shy;utväxlingen på applikations&shy;nivå.
    </p>
    <p>
        Jag har en del tankar om hur detta kommer att se ut vad det lider – återigen utgående från Java&shy;implementationen – 
        men eftersom det som sagt kommer bli så genomgående har jag än så länge bara kopierat in WS-server&shy;modulen från me-sidan och skruvat lite lätt på den. 
        Av samma anledning finns inga test för denna i <i>app/server</i>-repot för tillfället, 
        utan detta får anses vara täckt av ovanstående och/eller bli en fråga för när modulen bryts ut helt och hållet. Fortsättning följer.
    </p>
</section>
<section id="kmom05">
    <h2>Kmom05</h2>
    <p>
        Jag började med att skriva en MongoDB-inriktad variant av en <i>Repository</i>-modul även här, vilken jag snart delade upp i två moduler: 
        en som hanterar (och cachar undan) själva uppkopplingen och en som representerar en samling (<i>collection</i>) och erbjuder enkla CRUD-funktioner mot denna. 
        Upplägget påminner därmed om den första versionen av min <a href="https://packagist.org/packages/lrc-se/anax-repository"><i>Repository</i>-komponent</a> i <b>ramverk1</b>, 
        men är här något enklare och fungerar på ett lite annorlunda sätt (även bortsett från de asynkrona bitarna), då det man får ut från MongoDB-drivrutinen 
        skiljer sig en del från hur PDO fungerar.
    </p>
    <p>
        Till databasen valde jag att ta tillbaka <a href="http://www.student.bth.se/~kabc16/dbwebb-kurser/htmlphp/me//kmom06/me6/search.php">stjärn&shy;kryssarna</a> från <b>htmlphp</b>. 
        Kodstrukturen för frontend&shy;kopplingen är snarlik den jag använt i ett antal senare kurser, med partiella vyer och hjälp&shy;funktioner som tolkar och validerar indata, 
        med den uppenbara skillnaden att själva databas&shy;operationerna nu använder asynkrona anrop. 
        Den knivigaste pucken att lösa där var att se till så att anslutningen alltid stängs när HTTP-svaret skickats, 
        vilket jag inte ville lägga på operations&shy;nivå direkt i <code>db-repository</code> ifall man vill göra fler operationer efter varandra, 
        samt att få till en vettig felhantering med hjälp av Express.
    </p>
    <p>
        Det blev ingen sökfunktion den här gången, men däremot går det att filtrera <a href="/ships">listan</a> genom en kryssruta och sortera den genom att klicka på kolumn&shy;rubrikerna. 
        Standard&shy;sorteringen är i lagrings&shy;ordning, men eftersom MongoDB:s automatiska ID:n är så långa har jag valt att inte skriva ut dem i tabellen 
        (de visas dock vid redigering och radering). Det finns heller inga flash&shy;meddelanden eftersom servern (åtminstone så långt) saknar sessions&shy;komponent. 
        Använd funktionen "Återställ databas" för att läsa om datan från fil, då själva databasen inte ingår i repot.
    </p>
    <p>
        Här skall också nämnas att jag av kompatibilitets&shy;skäl behövt använda <code>.then()</code>-struktur på koden, 
        vilket inte blir lika "snyggt" som <code>async</code>/<wbr><code>await</code>, men å andra sidan är det inte heller fel att träna på den underliggande <code>Promise</code>-tekniken som sådan – 
        särskilt inte om man inte kan vara säker på att målmiljön verkligen stöder de senare konstruktionerna. Jag har gjort vad jag har kunnat för att hålla koden så rak och tydlig som möjligt ändå, 
        men det blir några upprepningar och nästlade strukturer på sina håll.
    </p>
    <p>
        "Integrationen" i applikationen består liksom i det förra momentet endast av att modulerna kopierats över; det är ännu för tidigt att avgöra exakt hur de skall användas, 
        så det kändes inte vara så stor mening med att implementera något tillfälligt bara för sakens skull. Det finns heller inga test för databas&shy;delarna, 
        varken i redovisa-repot eller i applikationen, helt enkelt därför att jag inte orkade/hann antingen mocka MongoDB eller sätta upp en fungerande testdatabas att kommunicera mot – 
        särskilt inte på ett sätt som garanterat fungerar även med de externa tjänsterna.
    </p>
    <p>
        Slutligen har jag uppdaterat me-sidans kodbas till att använda MVC-struktur fullt ut samt ändrat en del i den övriga katalog&shy;strukturen när jag ändå höll på, 
        så att det skall bli lite lättare att hitta saker och ting nu när projektet har växt. Observera även att databasdelen inte fungerar på student&shy;servern, 
        eftersom denna inte har stöd för MongoDB – vilket dock i sin tur illustrerar att tidigare omnämnda felhantering fungerar som den skall.
    </p>
    <h5>Hur gick det att komma igång med databasen MongoDB?</h5>
    <p>
        Det tog sin lilla tid detta, då arbetssättet skiljer sig markant från de tekniker jag utsatts för hittills, 
        både inom den akademiska världen, i arbetslivet samt privat – och då inkluderar jag såväl RDBMS som tidigare NoSQL-erfarenheter. 
        Man får helt enkelt lära sig att tänka annorlunda, men när man väl kommit över en viss tröskel så flyter det på.
    </p>
    <p>
        Rent tekniskt kör jag MongoDB i en alpine-behållare i förgrunden på min Debian-VM, eftersom det som tidigare nämnts bara är där som Docker fungerar, 
        och utvecklar Express-servern på huvud&shy;systemet. På detta sätt kan jag använda min normala utvecklings&shy;miljö 
        för själva kod&shy;knackandet och samtidigt enkelt hålla koll på logg&shy;utskrifter från databas&shy;motorn. 
        För Express-behållaren såg jag ingen anledning att använda en egen <i>Dockerfile</i> över huvud taget, så den definieras direkt i <i>docker-compose.yml</i> som tidigare 
        (behållarna från Kmom02 har nu flyttats till <i>docker-compose-old.yml</i>).
    </p>
    <h5>
        Vilken syn har du på databaser inom konceptet NoSQL?<br>
        Reflektera över skillnader och likheter mellan relations&shy;databaser och databaser inom NoSQL.
    </h5>
    <p>
        Jag ser absolut nyttan och attraktionen hos dem, särskilt när det kommer till möjligheterna att frigöra sig från rigida databas&shy;scheman, 
        då det öppnar upp för ett mer dynamiskt användande än med en traditionell relations&shy;databas. 
        Beroende på vad det är man vill lagra kan den fasta strukturen hos en tabell vara för begränsande, 
        alternativt att man nödgas införa ett flertal kolumner som endast utnyttjas sporadiskt och för det mesta bara innehåller <code>NULL</code>, 
        vilket t.ex. dokument&shy;databaser som MongoDB löser på ett mycket enklare sätt.
    </p>
    <p>
        Å andra sidan ställer BASE (kontra ACID) och den utbredda frånvaron av <code>JOIN</code>-operationer helt andra krav på applikationen, 
        där man ibland får göra en massa "kringgående rörelser" för att hantera sådant som är inbyggt även i det enklaste RDBMS. 
        Ett vanligt återkommande problem är att det kan vara svårt att avgöra om den information man får ut verkligen är aktuell, 
        samt att säkerställa att den information man skriver tillbaka verkligen lagras och i sin tur blir aktuell för andra läs&shy;operationer.
    </p>
    <p>
        NoSQL-databaser är också enklare att implementera i distribuerad form, med flera kommunicerande noder i ett nätverk, vilket gör dem mer skalbara än motsvarande relations&shy;databaser. 
        Detta är naturligtvis mycket användbart i dagens omgivning med allt mer molnbaserade tjänster och <i>big data</i>, 
        men det man offrar är alltså ofta de garantier som ACID medför liksom styrkan i relations&shy;baserade datamodeller och de möjligheter som därtill hörande SQL erbjuder.
    </p>
    <p>
        Alla tekniker under beaktning löser dock grund&shy;problemet i att lagra och tillgänglig&shy;göra relaterade data enligt godtyckliga uppdelningar, 
        där det på en basal nivå mest bara är namnen på begreppen som skiljer – det är hur dessa uppdelningar hanteras i ett större perspektiv som ger varje typ sin särart. 
        CRUD-operationer, selektion, projektion och sortering finns t.ex. i allmänhet att tillgå i en eller annan form oavsett motor, 
        men de kan bete sig olika beroende på vad som finns under huven enligt ovan.
    </p>
    <p>
        Slutsatsen blir densamma som alltid: allt har fördelar och nackdelar och man bör välja den teknik som passar bäst för det syfte man vill uppnå, i det sammanhang det skall uppnås.
    </p>
    <h5>Vilka är dina tankar om asynkron programmering med JavaScript?</h5>
    <p>
        Någon form av hatkärlek, tror jag. Det asynkrona och händelse&shy;baserade upplägget är ju som sagt en del av språkets grundvalar, 
        så det är inte direkt så att man kommer undan det, men när det kommer till t.ex. databas&shy;operationer som här, vilka i andra sammanhang (såsom dem vi stött på hittills) 
        varit rent sekventiella, blir skillnaderna mycket tydligare. I mångt och mycket är det en vanesak, vilket det även är att ställa om från <i>callback</i>-baserade 
        API:er till <code>Promise</code>-baserade diton, eller <code>async</code>/<wbr><code>await</code> nu senast då.
    </p>
    <p>
        Flera olika sätt att göra samma sak, helt enkelt, för själva upplägget som sådant är ju inget nytt för en gammal JS-räv – 
        även om man fortfarande snubblar över vissa saker till och från när någon form av ordning (sekvens) behöver upprätthållas.
    </p>
    <h5>Hur känner du för Docker och det sättet vi jobbar med tjänster i behållare?</h5>
    <p>
        Jag är väl inget jättefan. Visst kan det tyckas smidigt att bara kunna sparka igång självständiga saker kors och tvärs utan vidare, 
        men tidigare invändningar om duplicering och resurs&shy;utnyttjande kvarstår – varför sätta upp ett godtyckligt antal <em>fullständiga miljöer</em> 
        som endast skiljer sig åt i det <em>sista lagret</em> (applikationen)? Man binder sig även hårt till en specifik teknik, 
        där det som vi sett är långtifrån säkert att den faktiskt fungerar i alla sammanhang där det aktuella projektet kan tänkas behöva köras/<wbr>användas. 
        Detta gäller särskilt ifråga om den tänkta målmiljön, där specifika begränsningar <em>och möjligheter</em> kan finnas som man behöver förhålla sig till – 
        test och utveckling är en sak, produktions&shy;duglighet en annan.
    </p>
</section>
<section id="kmom06">
    <h2>Kmom06</h2>
    <h5>Reflektera över vikten av infrastruktur för moduler för ett programmerings&shy;språk.</h5>
    <p>
        Det är nog mer eller mindre nödvändigt för att språket ifråga skall få ordentlig spridning och nå framgång på allvar. 
        Utan en enkel modulhantering blir det ofta mycket manuellt arbete (nedladdning, uppackning, kopiering etc.) 
        och skelettkod som behöver skrivas varje gång man skall lyfta in något som någon annan gjort – eller också blir det inkluderingar rakt av, vilket t.ex. ofta var fallet förut med PHP.
    </p>
    <p>
        När det gäller JavaScript specifikt så har situationen som bekant länge varit något prekär i detta avseende, särskilt på klientsidan, 
        vilket är anledningen till att system som CommonJS, webpack och gulp vuxit fram för att man skall slippa hålla reda på asynkron tajming själv vid normal inläsning av flera skriptfiler. 
        Det blir intressant att se vilket genomslag modulsystemet i ES6 får framöver, liksom om det någonsin kommer att bli <a href="https://caniuse.com/#feat=es6-module">allmänt gångbart</a> 
        att göra motsvarande direkt i HTML.
    </p>
    <h5>Vill du ge dig på att förklara att just npm är den tjänst som växt snabbast av de modul&shy;kataloger som presenteras på webbplatsen “Module Counts”?</h5>
    <p>
        Utöver ovanstående lär det ha att göra med Nodes starka frammarsch de senaste åren, vilket i sin tur kan ses som en del i en större trend – JavaScript är helt enkelt i ropet nu, 
        när det gäller både klient, server och rent arbetsmarknads&shy;mässigt. På gott och ont, kan tyckas; vi har ju sett ett flertal artiklar som beklagat sig över den stora floran av JS-ramverk, 
        där det ett tag tycktes dyka upp ett nytt varje vecka, men jag får också uppfattningen att saker och ting börjar stabilisera sig en del, 
        om inte annat så i takt med att HTML5-API:er och ES6+ får allt större stöd ute i det vilda.
    </p>
    <h5>Reflektera över hur arbetet gick att välja, separera, publicera och sedan åter integrera modulen i din applikation.</h5>
    <p>
        Det var egentligen inga problem alls. Jag hade redan i <a href="#kmom04">Kmom04</a> valt att bryta ut en allmän <i>Web Sockets</i>-server till en egen modul, 
        så jag tog helt enkelt den koden och lade i ett eget repo (i <i>me/module</i>). Sedan var det bara att ändra på några sökvägar och köra <code>npm link</code> 
        så funkade allt direkt; därefter kunde jag enkelt skapa ett npm-konto och publicera samt installera modulen på riktigt. 
        Eftersom applikationen ännu inte är i närheten av att vara körbar har jag också installerat om den fristående modulen i me-sidan, 
        så chatten här använder sig nu av en npm-installation istället för lokal kod i repot (som tagits bort i och med att den blev överflödig).
    </p>
    <p>
        Själva <a href="https://www.npmjs.com/package/ws-server">modulen</a> är alltså mer eller mindre allmängiltig och är inte specifikt knuten till <a href="/chat">chattsystemet</a>, 
        utan det sistnämnda använder sig av den förstnämnda för att hantera anslutningarna. Efter Kmom04 har jag filat lite mer på koden och API:et 
        och det känns som att det hela nog skulle vara användbart i allehanda sammanhang nu. Speciellt nöjd är jag med införandet av <code>client</code>-objektet i händelse&shy;hanterarna, 
        vilket underlättade byggandet av chattservern och förmodligen kommer att vara avgörande vid byggandet av applikationen. Se modulens dokumentation för mer information.
    </p>
    <p>
        Om det är nånting som skall sägas så är det väl att man fick lov att klura ut allting själv med hjälp av npm-dokumentationen (som är delvis bristfällig) 
        ifråga om hela processen att skapa en ny publicerbar modul från noll, men det kanske också var tanken. Dessutom tog det en del tid att få till en bra testserie (100&nbsp;%, igen) 
        samt att, inte minst, skriva en bra och heltäckande dokumentation (pust).
    </p>
    <h5>Sista uppgiften om att dokumentera och färdigställa redovisa-sidan – tog den mycket tid eller hade du allt klart?</h5>
    <p>
        Det handlade bara om några extra meningar och någon liten justering här och var, då jag redan gjort det mesta i tidigare moment.
    </p>
</section>
<section id="kmom10">
    <h2>Kmom10</h2>
    <p>blubb</p>
</section>
